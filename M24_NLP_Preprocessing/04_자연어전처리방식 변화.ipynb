{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c459fe7",
   "metadata": {},
   "source": [
    "## 전통적인 데이터 전처리 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f158f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전통적인 방법으로 전처리된 텍스트:\n",
      "['단계적', '조치', '요구', '이행기간', '압축한', '큰', '거래', '원해', '폼페이오볼턴', '연일', '밑그림', '소개', '구체적', '답변안해트럼프', '미', '대통령과', '김정은', '북한', '국무위원장워싱턴dc', 'epa연합뉴스', '자료사진서울연합뉴스', '조준형', '기자', '다음', '달', '일', '싱가포르에서의', '도널드', '트럼프', '대통령과', '김정은', '국무위원장', '간', '세기의', '회담을', '앞둔', '가운데', '북미', '빅딜의', '윤곽이', '드러나고', '있다', '밑그림은', '트럼프', '미', '행정부의', '외교안보', '핵심인사들의', '입을', '통해', '소개되고', '있으나', '이에', '대해', '북한은', '구체적으로', '반응하지', '않고', '있다', '지금까지', '나온', '이들의', '발언을', '종합해보면', '북미', '빅딜의', '골자는', '트럼프', '대통령의', '첫', '임기', '사실상', '마지막', '해인', '년까지', '북한이', '비핵화를', '달성하면', '미국은', '국제사회의', '대북', '투자와', '경협을', '막는', '각종', '제재를', '해제하고', '북미', '수교와', '평화협정을', '체결하는', '등의', '내용인', '것으로', '보인다', '트럼프', '행정부에선', '존', '볼턴', '백악관']\n"
     ]
    }
   ],
   "source": [
    "# 전통적인 데이터 전처리 방법\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# 텍스트 파일 읽기\n",
    "with open('./data/naver_news.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 정제 (Cleaning)\n",
    "# 특수문자 제거\n",
    "cleaned_text = re.sub(r'[^가-힣a-zA-Z\\s]', '', text)\n",
    "\n",
    "# 소문자 변환\n",
    "cleaned_text = cleaned_text.lower()\n",
    "\n",
    "# 토큰화 (Tokenization)\n",
    "tokens = word_tokenize(cleaned_text)\n",
    "\n",
    "# 불용어 제거 (Stopword Removal)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "# 어간 추출 (Stemming)\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# 표제어 추출 (Lemmatization)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "print(\"전통적인 방법으로 전처리된 텍스트:\")\n",
    "print(lemmatized_tokens[:100])  # 전처리된 결과의 일부 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc469f5",
   "metadata": {},
   "source": [
    "- 한국어 형태소 분석기 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9f7c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okt를 사용한 전처리된 텍스트:\n",
      "['단계', '적', '조치', '요구', '이행', '기간', '압축', '한', '큰', '거래', '원해', '폼페이', '오', '볼턴', '연일', '밑그림', '소개', '구체', '적', '답변', '안해', '트럼프', '미', '대통령', '과', '김정은', '북한', '국무위원', '장', '워싱턴', '연합뉴스', '자료', '사진', '서울', '연합뉴스', '조준형', '기자', '다음', '달', '일', '싱가포르', '에서의', '도널드', '트럼프', '대통령', '과', '김정은', '국무위원', '장', '간', '세기', '의', '회담', '을', '앞둔', '가운데', '북미', '빅딜', '의', '윤곽', '드러나고', '있다', '밑그림', '은', '트럼프', '미', '행정부', '의', '외교', '안보', '핵심', '인사', '의', '입', '을', '통해', '소개', '되고', '있으나', '에', '대해', '북한', '은', '구체', '적', '으로', '반응', '하지', '않고', '있다', '지금', '까지', '나온', '의', '발언', '을', '종합', '해보면', '북미', '빅딜']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "# 텍스트 파일 읽기\n",
    "with open('./data/naver_news.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 정제 (Cleaning)\n",
    "# 특수문자 제거\n",
    "cleaned_text = re.sub(r'[^가-힣\\s]', '', text)\n",
    "\n",
    "# 형태소 분석기를 사용한 토큰화 및 불용어 제거\n",
    "okt = Okt()\n",
    "tokens = okt.morphs(cleaned_text)\n",
    "\n",
    "# 불용어 리스트 (예시)\n",
    "stop_words = {'이', '그', '저', '것', '수', '등', '들'}\n",
    "\n",
    "# 불용어 제거\n",
    "filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "print(\"Okt를 사용한 전처리된 텍스트:\")\n",
    "print(filtered_tokens[:100])  # 전처리된 결과의 일부 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c0a87d",
   "metadata": {},
   "source": [
    "## 딥러닝 기반 데이터 전처리 (BERT 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a09a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Downloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
      "   ---------------------------------------- 0.0/11.2 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 5.5/11.2 MB 30.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.2/11.2 MB 30.4 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "   ---------------------------------------- 0.0/558.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 558.8/558.8 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 36.2 MB/s eta 0:00:00\n",
      "Using cached torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, MarkupSafe, fsspec, filelock, jinja2, huggingface-hub, torch, tokenizers, transformers\n",
      "\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   -------------- -------------------------  4/11 [fsspec]\n",
      "   --------------------- ------------------  6/11 [jinja2]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [torch]\n",
      "   -------------------------------- -------  9/11 [tokenizers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ---------------------------------------- 11/11 [transformers]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.7.0 huggingface-hub-0.34.3 jinja2-3.1.6 mpmath-1.3.0 safetensors-0.5.3 sympy-1.14.0 tokenizers-0.21.4 torch-2.7.1 transformers-4.54.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec77d265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\cooju\\anaconda3\\envs\\crawl_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cooju\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT를 사용한 전처리된 토큰:\n",
      "['北', ',', '단', '##계', '##적', '조', '##치', '요', '##구', '[UNK]', '美', ',', '이', '##행', '##기', '##간', '압', '##축', '##한', \"'\", '큰', '거', '##래', \"'\", '원', '##해', '폼', '##페', '##이', '##오', '·', '볼', '##턴', ',', '연', '##일', '美', '밑', '##그', '##림', '소', '##개', '[UNK]', '北', ',', '구', '##체', '##적', '답', '##변', '##안', '##해', '##트', '##럼', '##프', '미', '대통령', '##과', '김', '##정', '##은', '북', '##한', '국', '##무', '##위', '##원', '##장', '[', '워', '##싱', '##턴', '##DC', 'EPA', '=', '연합뉴스', '자', '##료', '##사', '##진', ']', '(', '서울', '=', '연합뉴스', ')', '조', '##준', '##형', '기자', '=', '다음', '달', '12일', '싱', '##가', '##포', '##르', '##에서', '##의']\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 기반 데이터 전처리 (BERT 사용)\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# BERT 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 텍스트 파일 읽기\n",
    "with open('./data/naver_news.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# BERT 토크나이저를 사용한 토큰화\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"BERT를 사용한 전처리된 토큰:\")\n",
    "print(tokens[:100])  # 전처리된 결과의 일부 출력\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
